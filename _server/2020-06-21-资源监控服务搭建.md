## Prometheus+Grafana+Consul+Node Exporter+Cadvisor监控服务搭建(ubuntu)

[TOC]

1. ### 安装consul

下载地址：https://www.consul.io/downloads

官方consul地址：https://www.consul.io

解压consul_1.0.7_linux_amd64.zip，并将其移动到/usr/bin下，这样无论在哪个目录，都可以直接使用consul命令了。

```
[root@prometheus01 prometheus]# unzip consul_1.7.3_linux_amd64.zip
[root@prometheus01 prometheus]# mv consul /usr/bin/
```
执行consul version查看版本，检查是否安装成功。

```
[root@prometheus01 prometheus]# consul version
```
2. ### 启动单机版consul

```
consul agent -server -bootstrap-expect 1 -data-dir=/tmp/consul -node=agent-one -bind=172.17.12.192 -client=0.0.0.0 -ui &

```


运行cosnul agent以server模式，
```
-server ： 定义agent运行在server模式
-bootstrap-expect ：在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap共用
-bind：该地址用来在集群内部的通讯，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0
-node：节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名
-ui-dir： 提供存放web ui资源的路径，该目录必须是可读的
-rejoin：使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中。
-config-dir：配置文件目录，里面所有以.json结尾的文件都会被加载
-client：consul服务侦听地址，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1所以不对外提供服务，如果你要对外提供服务改成0.0.0.0
```

3. ### 下载consul-template

```
#选择对应需要下载的系统和版本
https://releases.hashicorp.com/consul-template/
unzip xxxx.zip
cp consul-template /usr/local/bin
consul-template -version
```
- #### 创建consul-template的配置文件
配置文件示例如下：
```
log_level = "warn"
syslog {
# This enables syslog logging.
enabled = true
# This is the name of the syslog facility to log to.
facility = "LOCAL5"
}
consul {
# auth {
# enabled = true
# username = "test"
# password = "test"
# }
address = "172.17.12.192:8500"
# token = "abcd1234"
retry {
enabled = true
attempts = 12
backoff = "250ms"
# If max_backoff is set to 10s and backoff is set to 1s, sleep times
# would be: 1s, 2s, 4s, 8s, 10s, 10s, ...
max_backoff = "3m"
}
}
template {
source = "/usr/local/prometheus/templates/discovery.ctmpl"
destination = "/usr/local/prometheus/conf.d/discovery.json"
command = ""
command_timeout = "60s"
backup = true
left_delimiter = "{$"
right_delimiter = "$}"
wait {
min = "2s"
max = "20s"
}
}
```

主要配置参数：

```
syslog: 启用syslog，这样服务日志可以记录到syslog里。

consul: 这里需要设置consul服务发现的地址，我这里无需认证，所以把auth注释了。consul服务的搭建可以参考我之前的文章。值得一提的是，backoff和max_backoff选项，backoff设置时间间隔，当未从consul获取到数据时会进行重试，并以2的倍数的时间间隔进行。比如设置250ms，重试5次，那么每次的时间间隔为：250ms,500ms,1s,2s,4s，直到达到max_backoff的阀值；如果max_backoff设为2s，那么第五次重试的时候还是间隔2s，即250ms,500ms,1s,2s,2s。

template：定义模板文件位置。主要选项是source，destination和command，当backup=true的时候，会备份上一次的配置，并以bak后缀结尾。

source：consul-template的模板文件，用来进行渲染的源文件。

destination：consul-template的模板被渲染之后的文件位置。比如这里即是我prometheus基于文件发现的子配置文件位置:/usr/local/prometheus/conf.d/下的文件。

command:文件渲染成功之后需要执行的命令。prometheus这里会自动发现文件的更改，所以我这里无需任何命令，给注释掉了。像nginx、haproxy之类的服务，一般更改完配置文件之后都需要重启，这里可以设置“nginx -s reload”之类的命令。

command_timeout：设置上一步command命令执行的超时时间。

left_delimiter和right_delimiter：模板文件中分隔符。默认是用“{{}}”设置模板，当产生冲突的时候可以更改这里的设置。比如我这里由于用ansible去推送的模板文件，“{{}}”符号与Jinja2的语法产生了冲突，所以改为了“{$$}”符号。
```
4. ### 启动consul-template服务

创建文件

```
source = "/usr/local/prometheus/templates/discovery.ctmpl"
destination = "/usr/local/prometheus/conf.d/discovery.json"
```


```
启动consul-template服务，指定配置文件。

#./consul-template -config ./consul-template.conf
```
5. ### 模板渲染
这里首先得在consul服务中创建prometheus/baas/文件夹。

- 可通过浏览器访问http://{consul IP}}:8500/consul服务创建
```
[root@prometheus01 prometheus]# cat templates/redis-discovery.ctmpl 
[
{$ range tree "prometheus/baas" $}
{
"targets": ["{$ .Value $}"],
"labels": {
"instance": "{$ .Key $}",
"env": "pre-product"
}
},
{$ end $}
{
"targets": ["localhost:9090"],
"labels": {
"instance": "prometheus01",
"env": "pre-product"
}
}
]
```
6. ### 拉取Prometheus镜像

```
 docker pull prom/prometheus
```
7. ### Prometheus安装
- Prometheus的配置文件样例

```
#全局配置项
global:
 scrape_interval: 30 # 设定抓取数据的周期，默认为1min
 evaluation_interval: 30 # 设定更新rules文件的周期，默认为1min
 scrape_timeout: 15s # 设定抓取数据的超时时间，默认为10s

# scape配置
scrape_configs:
- job_name: 'prometheus' # job_name默认写入timeseries的labels中，可以用于查询使用
  scrape_interval: 15s # 抓取周期，默认采用global配置
  static_configs: # 静态配置
   - targets: ['123.57.73.14:9100', '123.57.73.14:9090','123.57.73.14:9080'] # prometheus所要抓取数据的地址，即instance实例项

#- job_name: 'prometheus1' #个人测试用接口
# static_configs:
# - targets: ['192.168.3.152:9100','192.168.3.152:9080']
```
- Prometheus基于文件的服务发现–“file_sd_config”

```
#全局配置项
#全局配置项
global:
 scrape_interval: 60s # 设定抓取数据的周期，默认为1min
 evaluation_interval: 30s # 设定更新rules文件的周期，默认为1min
 scrape_timeout: 15s # 设定抓取数据的超时时间，默认为10s
# scape配置
scrape_configs:
- job_name: 'baas'
  file_sd_configs:
    - files:
      - /usr/local/prometheus/conf.d/*.json
```
prometheus 实时更新./conf.d/下以.json结尾的文件。有变化自动更新到prometheus的监控页面上展示。

 
- file_sd_config参考样例

```
[root@prometheus01 prometheus]# cat conf.d/targets.json |more
[
  {
    "targets": [ "100.100.110.71:9090" ],
    "labels": {
      "env": "product",
      "job": "prometheus",
      "instance": "100.100.110.71_prometheus_server"
    }
  },
  {
    "targets": [ "100.100.110.53:9121" ],
    "labels": {
      "env": "product",
      "job": "redis",
      "instance": "redis53"
    }
   }
]
```
8. ### 启动Prometheus

```
docker run -d -p 9090:9090 --name prometheus --net=host -v /root/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml -v /usr/local/prometheus/conf.d/:/usr/local/prometheus/conf.d/ prom/prometheus --storage.tsdb.retention.time=1d --config.file=/etc/prometheus/prometheus.yml
```
主要配置参数：

```
/root/prometheus/prometheus.yml 为配置文件的绝对路径
/usr/local/prometheus/conf.d/ 为存放file_sd_config模板的目录
--storage.tsdb.retention.time 为Prometheus数据存储时长
```

9. ### 拉取Grafana镜像

```
docker pull rafana/grafana
```

10. ### Grafana创建Mysql数据库

```
创建库名和和账户授权：
create database grafana DEFAULT CHARACTER SET utf8mb4 ;
GRANT ALL ON grafana.* TO grafana@'%' IDENTIFIED BY 'grafanap' WITH GRANT OPTION;

```
11. ### 启动Grafana

替换命令中的数据库信息
```
docker run -itd --name grafana -p 3000:3000 -e "GF_AUTH_PROXY_ENABLED=true" -e "GF_AUTH_ANONYMOUS_ENABLED=true" -e "GF_DATABASE_TYPE=mysql" -e "GF_DATABASE_HOST=172.17.12.196:3306" -e "GF_DATABASE_NAME=grafana" -e "GF_DATABASE_USER=grafana" -e "GF_DATABASE_PASSWORD=grafanap" grafana/grafana
```
- #### 导入指定数据源和模板dashboard

- 修改data_source.sql文件中的prometheus数据源路径。

-  将dashboard.sql、data_source.sql导入Grafana数据库。

12. ### 安装Node Exporter(Baas平台不需要安装，集群会自动启动)


```
sudo docker run -d -p 9100:9100 \
-v "/proc:/host/proc" \
-v "/sys:/host/sys" \
-v "/:/rootfs" \
prom/node-exporter \
--path.procfs /host/proc \
--path.sysfs /host/sys \
--collector.filesystem.ignored-mount-points "^/(sys|proc|dev|host|etc)($|/)"

```
13. ### 安装Cadvisor(Baas平台不需要安装，集群会自动启动)

```
docker run -d \
--volume=/:/rootfs:ro \
--volume=/var/run:/var/run:rw \
--volume=/sys:/sys:ro \
--volume=/var/lib/docker/:/var/lib/docker:ro \
--publish=9080:8080 \
--detach=true \
--name=cadvisor \
-v "/etc/localtime:/etc/localtime" \
google/cadvisor:latest

```



